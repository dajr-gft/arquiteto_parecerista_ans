# üéØ Vertex AI Evaluation - BV ANS Agent

Avalia√ß√£o gerenciada com dashboards visuais e armazenamento centralizado usando **Vertex AI Evaluation Service**.

---

## üìã Vis√£o Geral

Este m√≥dulo fornece avalia√ß√£o enterprise-grade do agente BV ANS usando a infraestrutura Google Cloud, ideal para:
- ‚úÖ Avalia√ß√µes pr√©-produ√ß√£o
- ‚úÖ Compara√ß√£o A/B entre vers√µes
- ‚úÖ Relat√≥rios executivos com dashboards
- ‚úÖ Hist√≥rico de avalia√ß√µes no BigQuery
- ‚úÖ Auditorias e compliance
- ‚úÖ Monitoramento cont√≠nuo de qualidade

---

## üöÄ Setup Inicial

### **1. Instalar Depend√™ncias**

```bash
cd bv_ans/testes/eval/vertex_ai_evaluation
pip install -r requirements_vertex_ai.txt
```

### **2. Configurar GCP**

```bash
# Autenticar
gcloud auth application-default login

# Definir projeto
gcloud config set project gft-bu-gcp

# Habilitar APIs necess√°rias
gcloud services enable aiplatform.googleapis.com
gcloud services enable storage.googleapis.com
gcloud services enable bigquery.googleapis.com
```

### **3. Criar Recursos GCS e BigQuery**

O script cria automaticamente:
- **GCS Bucket**: `gft-bu-gcp-eval-staging`
- **BigQuery Dataset**: `bv_ans_evaluation`
- **BigQuery Table**: `evaluation_results`

---

## üéØ Executar Avalia√ß√£o

### **Avalia√ß√£o Completa com Vertex AI**

```bash
python run_vertex_ai_evaluation.py
```

Isso ir√°:
1. ‚úÖ Criar dataset de avalia√ß√£o no GCS
2. ‚úÖ Executar avalia√ß√£o gerenciada no Vertex AI
3. ‚úÖ Salvar resultados no BigQuery
4. ‚úÖ Gerar link para dashboard visual
5. ‚úÖ Salvar relat√≥rio local

### **Visualizar Resultados**

Ap√≥s a execu√ß√£o, voc√™ receber√°:

1. **Console Output**:
   ```
   ‚úÖ Evaluation completed!
   üìä Dashboard URL: https://console.cloud.google.com/vertex-ai/...
   üíæ Results saved to BigQuery: bv_ans_evaluation.evaluation_results
   ```

2. **Dashboard Visual** (Google Cloud Console):
   - M√©tricas agregadas
   - Compara√ß√£o entre testes
   - Breakdown por categoria
   - Hist√≥rico de execu√ß√µes

3. **BigQuery** (para an√°lises customizadas):
   ```sql
   SELECT 
     evaluation_id,
     display_name,
     timestamp,
     metrics_summary
   FROM `gft-bu-gcp.bv_ans_evaluation.evaluation_results`
   ORDER BY timestamp DESC
   LIMIT 10;
   ```

---

## üìä Vantagens sobre ADK Local

| Recurso | ADK Local | Vertex AI |
|---------|-----------|-----------|
| Dashboard Visual | ‚ùå | ‚úÖ Console interativo |
| Hist√≥rico Centralizado | ‚ùå | ‚úÖ BigQuery |
| Compara√ß√£o de Vers√µes | Manual | ‚úÖ Autom√°tica |
| M√©tricas Automatizadas | Limitado | ‚úÖ Safety, Groundedness, Tool Use |
| Escalabilidade | Local | ‚úÖ Cloud managed |
| Relat√≥rios Executivos | HTML b√°sico | ‚úÖ Dashboards profissionais |
| Auditoria | JSON local | ‚úÖ BigQuery audit√°vel |

---

## üîß Configura√ß√£o Avan√ßada

### **Customizar Avalia√ß√£o**

Edite `run_vertex_ai_evaluation.py`:

```python
config = VertexAIEvaluationConfig(
    project_id="gft-bu-gcp",
    location="us-central1",
    staging_bucket="meu-bucket-eval",
    bigquery_dataset="meu_dataset_eval",
    evaluation_display_name="BV-ANS-v2.0-eval"
)
```

### **Adicionar M√©tricas Vertex AI Padr√£o**

O Vertex AI Evaluation Service inclui m√©tricas autom√°ticas:

- **Safety**: Detec√ß√£o de conte√∫do inseguro/inapropriado
- **Groundedness**: Ader√™ncia a fontes/documentos
- **Fluency**: Flu√™ncia e naturalidade do texto
- **Tool Use Quality**: Qualidade no uso de ferramentas
- **Fulfillment**: Atendimento completo √† requisi√ß√£o

Para habilitar:

```python
# Em vertex_ai_evaluation.py
metrics = [
    "safety",
    "groundedness",
    "tool_use_quality",
    "fulfillment"
]
```

---

## üìà An√°lises no BigQuery

### **Evolu√ß√£o de Scores ao Longo do Tempo**

```sql
SELECT 
  DATE(timestamp) as data,
  AVG(JSON_VALUE(metrics_summary, '$.overall_score')) as avg_score,
  COUNT(*) as num_evaluations
FROM `gft-bu-gcp.bv_ans_evaluation.evaluation_results`
WHERE agent_id = 'bv_ans_agent'
GROUP BY data
ORDER BY data DESC;
```

### **Comparar Duas Vers√µes**

```sql
WITH v1 AS (
  SELECT * FROM `gft-bu-gcp.bv_ans_evaluation.evaluation_results`
  WHERE display_name LIKE '%v1.0%'
  ORDER BY timestamp DESC LIMIT 1
),
v2 AS (
  SELECT * FROM `gft-bu-gcp.bv_ans_evaluation.evaluation_results`
  WHERE display_name LIKE '%v2.0%'
  ORDER BY timestamp DESC LIMIT 1
)
SELECT 
  'v1.0' as version,
  JSON_VALUE(v1.metrics_summary, '$.overall_score') as score
FROM v1
UNION ALL
SELECT 
  'v2.0' as version,
  JSON_VALUE(v2.metrics_summary, '$.overall_score') as score
FROM v2;
```

### **Identificar Testes com Falhas Recorrentes**

```sql
SELECT 
  JSON_VALUE(metrics_summary, '$.test_id') as test_id,
  COUNT(*) as num_failures,
  AVG(JSON_VALUE(metrics_summary, '$.score')) as avg_score
FROM `gft-bu-gcp.bv_ans_evaluation.evaluation_results`,
  UNNEST(JSON_QUERY_ARRAY(metrics_summary, '$.failed_tests')) as failed_test
WHERE status = 'completed'
GROUP BY test_id
HAVING num_failures > 3
ORDER BY num_failures DESC;
```

---

## üé® Dashboard Vertex AI Console

Acesse: `https://console.cloud.google.com/vertex-ai/generative/evaluate`

**Recursos do Dashboard**:

1. **Overview**:
   - Score geral da √∫ltima avalia√ß√£o
   - Tend√™ncia ao longo do tempo
   - Compara√ß√£o com baseline

2. **Test Cases**:
   - Lista todos os casos de teste
   - Filtros por categoria, status, score
   - Drill-down em cada teste

3. **Metrics Breakdown**:
   - Gr√°ficos de cada m√©trica
   - Distribui√ß√£o de scores
   - Identifica√ß√£o de outliers

4. **Comparisons**:
   - Comparar duas avalia√ß√µes
   - Ver diferen√ßas de score
   - Identificar regress√µes

5. **History**:
   - Hist√≥rico completo
   - Export para CSV/JSON
   - Anota√ß√µes e coment√°rios

---

## üêõ Troubleshooting

### **Erro: "Permission denied"**

```bash
# Garantir permiss√µes necess√°rias
gcloud projects add-iam-policy-binding gft-bu-gcp \
  --member="user:seu-email@gft.com" \
  --role="roles/aiplatform.user"

gcloud projects add-iam-policy-binding gft-bu-gcp \
  --member="user:seu-email@gft.com" \
  --role="roles/bigquery.dataEditor"
```

### **Erro: "Bucket already exists"**

```python
# Em run_vertex_ai_evaluation.py, use bucket existente
config = VertexAIEvaluationConfig(
    staging_bucket="existing-bucket-name"
)
```

### **Evaluation n√£o aparece no Console**

1. Verifique o projeto correto no Console
2. Aguarde alguns minutos (processamento ass√≠ncrono)
3. Verifique regi√£o (deve ser us-central1)
4. Confira logs em Cloud Logging

---

## üìö Documenta√ß√£o Oficial

- [Vertex AI Evaluation API](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview)
- [Agent Evaluation Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-agents)
- [Custom Metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-metrics)
- [BigQuery ML](https://cloud.google.com/bigquery-ml/docs)

---

## üìû Suporte

**D√∫vidas sobre Vertex AI Evaluation?**
- Time de Arquitetura: arquitetura@bancobv.com.br
- GFT BU GCP: bucp@gft.com
- Google Cloud Support: Abra caso via Console

---

**Desenvolvido com ‚ù§Ô∏è pelo Time de Arquitetura - Banco BV & GFT**

